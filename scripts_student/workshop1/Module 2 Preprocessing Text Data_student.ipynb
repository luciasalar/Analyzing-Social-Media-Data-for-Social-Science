{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344dbfb4",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "In this module, you will learn how to do data cleaning:\n",
    "\n",
    "1. Remove punctuations\n",
    "2. Lowering text\n",
    "3. Removing URLs \n",
    "4. Tokenization (Chinese)\n",
    "5. Remove stop words\n",
    "6. Stemming\n",
    "7. Replacing emoji with text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ce2e3",
   "metadata": {},
   "source": [
    "# Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39582af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bb5b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation   #these are the punctuations contained in the library "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1dca6",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce28ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The cat~ says meow..!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec515dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat says meow\n"
     ]
    }
   ],
   "source": [
    "punctuation_free = []\n",
    "for character in sentence:\n",
    "    if character not in string.punctuation:\n",
    "        punctuation_free.append(character)\n",
    "        no_pun_sentence = \"\".join(punctuation_free) \n",
    "       \n",
    "print(no_pun_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fab8ce9",
   "metadata": {},
   "source": [
    "## Alternatively, you can write this in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac7bef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat says meow\n"
     ]
    }
   ],
   "source": [
    "no_pun_sentence = \"\".join([character for character in sentence if character not in string.punctuation]) \n",
    "       \n",
    "print(no_pun_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3853618",
   "metadata": {},
   "source": [
    "## Task 1: Remove punctuations in the tweets\n",
    "\n",
    "hint: \n",
    "\n",
    "access each tweet element in the dictionary, identify elements that are not in the string library\n",
    "\n",
    "join the elements using \"\".join(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = {\n",
    "  1: {\"userid\": \"000234\",\n",
    "  \"Tweet\": \"That strange moment when someone reminds the teacher about the homework.\"},\n",
    "  2: {\"userid\": \"002214\",\n",
    "  \"Tweet\": \"Hey, I get really nervous when I see others studying so much before the test.!!\"},     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e0f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514a748f",
   "metadata": {},
   "source": [
    "# Lowering text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48f70701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the cat~ says meow..!!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The cat~ says meow..!!\"\n",
    "sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9988f",
   "metadata": {},
   "source": [
    "## Task 2: Remove punctuations in the tweets (dictionary structure)\n",
    "\n",
    "using tweet_dict as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee409018",
   "metadata": {},
   "source": [
    "# Remove URLs\n",
    "\n",
    "\n",
    "Regular expression syntax let you check if a particular string matches a given regular expression \n",
    "\n",
    "Here's a quick start for you https://www.rexegg.com/regex-quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea9b63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16338f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_url = \"The course materials are on https://lushichen.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca233bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The course materials are on '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"http\\S+\", \"\", sentence_url) # means substitute \"http+a string of non-whitespace characters\" with \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e2ed0",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4442ea4",
   "metadata": {},
   "source": [
    "We already learnt the English tokenization in the previous module, task 7: split words in sentence\n",
    "\n",
    "In some languages, the boundary of a word is not separated by space, we need some packages to help with tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec3f2a",
   "metadata": {},
   "source": [
    "## Tokenizing Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b313f",
   "metadata": {},
   "source": [
    "jieba: \"Jieba\" (Chinese for \"to stutter\") Chinese text segmentation\n",
    "\n",
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b4692160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f358ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('于吉', freq=None, tag='nr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "92478755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赵小刚 nr\n",
      "曾经 d\n",
      "采访 v\n",
      "过 ug\n",
      "一位 m\n",
      "意大利 ns\n",
      "厨师 n\n",
      "， x\n",
      "他 r\n",
      "十几年 m\n",
      "前来 n\n",
      "过 ug\n",
      "中国 ns\n",
      "， x\n",
      "去 v\n",
      "了 ul\n",
      "不少 d\n",
      "地方 n\n",
      "， x\n",
      "他 r\n",
      "喜欢 v\n",
      "川菜 n\n",
      "， x\n",
      "对 p\n",
      "粤菜 n\n",
      "也 d\n",
      "颇为 v\n",
      "上瘾 v\n",
      "， x\n",
      "他 r\n",
      "好奇 a\n",
      "中餐 n\n",
      "这么 r\n",
      "好吃 v\n",
      "， x\n",
      "高级 b\n",
      "的 uj\n",
      "饭馆 n\n",
      "为什么 r\n",
      "这么 r\n",
      "少 a\n"
     ]
    }
   ],
   "source": [
    "text = \"赵小刚曾经采访过一位意大利厨师，他十几年前来过中国，去了不少地方，他喜欢川菜，对粤菜也颇为上瘾，他好奇中餐这么好吃，高级的饭馆为什么这么少\"\n",
    "words = pseg.cut(text)\n",
    "for w in words:\n",
    "    print('%s %s' % (w.word, w.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685e18f",
   "metadata": {},
   "source": [
    "## Customize word boundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e3dd5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('前来', tune=True)  # you want to reduce this word frequency so that jieba doesn't cut it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "99122c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('前来', freq=10, tag='n') #adjust frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "95bbaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他 r\n",
      "十几年 m\n",
      "前 f\n",
      "来过 n\n",
      "中国 ns\n"
     ]
    }
   ],
   "source": [
    "text = \"他十几年前来过中国\"\n",
    "words = pseg.cut(text)\n",
    "for w in words:\n",
    "    print('%s %s' % (w.word, w.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ffcbc",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "\n",
    "install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d392c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b7738bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/luciachen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f2fb4cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6f10449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Hey, I get really nervous when I see others studying so much before the test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0214077",
   "metadata": {},
   "source": [
    "#### the stopword dictionary is lower case, we need to lower case the sentence before we search for stop words in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac2246e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey,', 'get', 'really', 'nervous', 'see', 'others', 'studying', 'much', 'test']\n"
     ]
    }
   ],
   "source": [
    "output= [i for i in sentence.lower().split(' ') if i not in stopwords]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b992b",
   "metadata": {},
   "source": [
    "## Task 2:  Customize the stopword list in nltk\n",
    "\n",
    "we want to remove the word 'hey' from the sentence, add this word to nltk stopword list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606d5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65022c0c",
   "metadata": {},
   "source": [
    "# Stemming \n",
    "\n",
    "taking the root/base form of the word, for example, 'programming' -> \"program\", \"speaks\" -> \"speak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d6e89220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "65d84655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the object for stemming\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a0f39a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey,', 'i', 'get', 'realli', 'nervou', 'when', 'i', 'see', 'other', 'studi', 'so', 'much', 'befor', 'the', 'test']\n"
     ]
    }
   ],
   "source": [
    "stem_text = [porter_stemmer.stem(word) for word in sentence.split(' ')]\n",
    "print(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a4396",
   "metadata": {},
   "source": [
    "# Replace emmoji with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "59d0d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9d918d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game is on fire fire'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"game is on 🔥 🔥\"\n",
    "emoji.demojize(text, delimiters=(\"\", \"\"))  # 'game is on fire fire'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b9598",
   "metadata": {},
   "source": [
    "# Task 3: Write a function to preprocess text \n",
    "\n",
    "Joining all the previous steps into one function\n",
    "\n",
    "Here's how you define a function in Python\n",
    "\n",
    "def my_function(arg1, arg2):\n",
    "\n",
    "    do something\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "acd1ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"hey, I want to organize a BBQ tonight 🔥 🔥, do you want to join?\"\n",
    "\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5870168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a2ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa96c995",
   "metadata": {},
   "source": [
    "# Task 4: Preprocess tweets in dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7b6ef666",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dict = {\n",
    "  1: {\"userid\": \"000234\",\n",
    "  \"Tweet\": \"That strange moment when someone reminds the teacher about the homework.\"},\n",
    "  2: {\"userid\": \"002214\",\n",
    "  \"Tweet\": \"Hey, I get really nervous when I see others studying so much before the test.🔥 🔥!!\"},     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "573348cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweets):\n",
    "    \n",
    "        \n",
    "    return new_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edd0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1295a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e4223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
